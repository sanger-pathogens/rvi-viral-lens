// Copyright (C) 2023 Genome Surveillance Unit/Genome Research Ltd.

includeConfig "./conf/containers.config"
includeConfig "./rvi_toolbox/nextflow-commons.config"

manifest {
    name            = 'Viral Lens'
    author          = 'ARD'
    homePage        = 'https://github.com/genomic-surveillance/rvi-viral-lens'
    description     = 'identify the presence of Flu, SARS-CoV-2 and RSV and obtain, if possible, high quality consensus sequences for those virus.'
    mainScript      = 'main.nf'
    nextflowVersion = '>=24.10.3'
    version         = 'v1.4.1'
}

plugins {
  id 'nf-schema@2.2.0'
}

params {

    // -- REQUIRED INPUT --//
    manifest = null

    // kraken database
    db_path = null
    db_library_fa_path = null
    // ---------------------- //

    // --- SET PIPELINE DEFAULT PARAMETERS --//

    // --- general pipeline
    // set where output files should be published
    outdir = "$launchDir/results/"

    // scov2 subtyping switchs
    do_scov2_subtyping = true

    // preprocessing of reads switch
    do_preprocessing = false
    run_trimmomatic = true
    run_trf = true
    run_hrr = true
    publish_clean_reads = false
    debug_preproc_output = false


    // --- SET WORKFLOW SPECIFIC DEFAULT PARAMETERS --- //

    // -- SUBTYPING
    // virus subtyping branching keywords
    scv2_keyword = "Severe acute respiratory syndrome coronavirus 2"

    // -- kraken
    kraken2_mem = "2.GB"
    kraken2_cpus = 4

    // -- Kraken2ref (k2r)
    k2r_polling_mode = "max"

    // kraken report minum number of reads filter
    min_reads_for_taxid = 100

    // set maximum number of reads to be accepted
    k2r_max_total_reads_per_fq = 10000000
    // any fastq file pair with more than that number of reads
    // will be splitted into N chunks, each containing that maximum
    // amount of reads to be processed by k2r. Those splitted files
    // are intemediate files and the final output will still be per
    // reported per sample.

    // ---------------------- //
    // -- CONSENSUS GENERATION
    // for original viral_lens (pre introduction of minimap2 and polishing), do:
    //   do_consensus_polishing = false
    //   read_aligner = "bwa"
    //   read_aligner_params = ""
    //   mpileup_max_depth = 0
    //   ivar_initial_min_depth = 10
    //   ivar_initial_freq_threshold = 0.75
    do_consensus_polishing = true
    read_aligner = "minimap2"
    read_aligner_params = "-ax sr -k11 -w 4"
    mpileup_max_depth = 2000
    ivar_initial_min_depth = 1
    ivar_initial_freq_threshold = 0.60
    ivar_polish_min_depth = 10
    ivar_polish_freq_threshold = 0.75
    // ---------------------- //

    // debug options
    developer_publish = false

    // nextclade
    nextclade_index_json = null
}

// Execution layer settings

process {
    // Set pipelines outputs
    // -- standard outputs
    withLabel: consensus_output {
        publishDir = [
            path: {"${params.outdir}/${meta.sample_id}/${meta.taxid}/"},
            overwrite: true,
            mode: "copy"
        ]
    }

    withLabel: run_output {
        publishDir = [
            path: {"${params.outdir}/"},
            overwrite: true,
            mode: "copy"
        ]
    }

    withLabel: kraken {
        publishDir = [
            path: {"${params.outdir}/${meta.sample_id}/"},
            mode: 'copy',
            pattern: "*.kraken_report.txt"
        ]
    }

    // -- intermediate outputs
    withLabel: get_taxid_reference_files {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/developer_publish/reference_files/"},
                mode: 'copy'
        ]
    }
    withLabel: pangolin {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/developer_publish/${meta.sample_id}/${meta.taxid}/"},
                mode: 'copy',
                pattern: "*.csv"
        ]
    }

    withLabel: ivar {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/developer_publish/${meta.sample_id}/${meta.taxid}/"},
                mode: 'copy',
                pattern: "*.{txt,tsv,csv}"
        ]
    }

    withLabel: kraken2ref {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/developer_publish/${meta.sample_id}/reads_by_taxon/"},
                mode: 'copy',
                pattern: "*.{tsv,fq,json}"
        ]
    }


}

profiles {
    
    standard {

        docker {
            enabled = false
        }

        singularity {
            enabled = true
            autoMounts = true
            runOptions = '--writable-tmpfs'
        }

        process {
            // by default nextflow commons (1 cpu, 1GB, 1h)
            cache='lenient'
            executor='local'
        }

    }

    sanger_standard {
        params {
            max_retries = 3
            max_memory = 128.GB // 2.9.TB
            max_cpus = 32 // 256
            max_time = 6.h // 720.h
        }

        docker {
            enabled = false
        }

        singularity {
            enabled = true
            autoMounts = true
            runOptions = "--bind /lustre,/nfs,/software,/data/"
        }

        process {
            // by default nextflow commons (1 cpu, 1GB, 1h)
            cache='lenient'
            executor='local'

            // settings for tasks submitted to LSF
            queue = { task.memory > 745.GB ? 'teramem' :
                      task.memory > 196.GB ? 'hugemem' :
                      task.time <= 30.m ? 'small' :
                      task.time <= 12.h ? 'normal' :
                      task.time <= 48.h ? 'long' :
                      task.time <= 168.h ? 'week' :
                      'basement'}

            // run k2r on lsf
            withName: run_k2r_sort_reads{
                executor = 'lsf'
            }

            withName: run_k2r_dump_fastqs_and_pre_report{
                executor = 'lsf'
            }

            // run kraken2 on lsf
            withName: run_kraken {
                executor = 'lsf'
                cpus = params.kraken2_cpus
                memory = {
                    def base_mem = params.kraken2_mem as nextflow.util.MemoryUnit
                    return base_mem * task.attempt
                }
            }

            withName: run_aligner {
                executor = 'lsf'
            }

            withName: run_ivar {
                executor = 'lsf'
                memory = {  (task.attempt == 1) ? 1.GB : 8.GB * (task.attempt - 1) }
            }

            withName: run_pangolin {
                executor = 'lsf'
            }

            withName: run_nextclade {
                executor = 'lsf'
                memory = {  (task.attempt == 1) ? 1.GB : 4.GB * (task.attempt - 1) }
            }

            // preprocessing steps on lsf
            withName:TRIMMOMATIC {
                executor = "lsf"
            }

            withName:FASTQ2FASTA {
                executor = "lsf"
            }

            withName:TRF {
                executor = "lsf"
            }

            withName:RMREPEATFROMFASTQ {
                executor = "lsf"
            }

            withName:SEQTK_MERGEPE {
                executor = "lsf"
            }

            withName:SRA_HUMAN_SCRUBBER {
                executor = "lsf"
            }

            withName:SEQTK_SPLIT {
                executor = "lsf"
            }

            //NOTE: processes that default to local execution:
            // get_taxid_reference_files
            // publish_consensus_files, publish_run_files
            // run_qc_script
            // write_properties_json

        }
        executor {
            jobName={ "RVI-viral-lens - $task.name - $task.tag" }
            perJobMemLimit=true

        }
    }
}

//---| memory escalation for k2r_sort_reads |

params {
    max_attempts = 3
    default_error_strategy = "terminate" // ["retry" or "terminate"]
    // attempt 1 -> y_pred = [(b0 + b0_offset) + b1*x]
    // attempt 2 -> y_pred * f1
    // attempt > 2 -> y_pred + a2
    mem_k2r_b0_offset = 2 // GB
    mem_k2r_b0= 1.23932729
    mem_k2r_b0_final = params.mem_k2r_b0 + params.mem_k2r_b0_offset
    mem_k2r_b1= 3.57231124
    mem_k2r_f1 = 1.5
    mem_k2r_a2 = 2
}

def bytesToSize(bytes, unit) {
    def values = [
        'B' : 1,
        'KB': 1024,
        'MB': 1024 * 1024,
        'GB': 1024 * 1024 * 1024
    ]

    def factor = values.get(unit)
    if (factor == null) {
        throw new Exception("Invalid unit: ${unit}")
    }

    return bytes / factor
}

def linear_regression_fit(x, b0, b1) {
    // y_pred = b0 + b1*x
    return b0 + b1*x
}

def retry_strategy(task, max_attempts, default_error_strategy){
    // this is borrow directly from PAM nextflow commons
    //
    def MISC_EXIT_CODES = [
        "SIGKILL": 137,
        "SIGTERM": 143,
        "SIGABRT": 134,
        "SIGSEGV": 139
    ].values()

    def SCALING_EXIT_CODES = [
        // see https://ssg-confluence.internal.sanger.ac.uk/pages/viewpage.action?pageId=101361150
        // LSF Runlimit exceeded or Out of memory Error; first signal allowing to quit cleanly
        "SIGUSR2": 140,

        // LSF Runlimit exceeded or Out of memory Error or bkill; second signal sent shortly
        // after the SIGUSR2 to make it quit if not done yet
        "SIGINT": 130,

        // LSF Runlimit exceeded or Out of memory Error; apparently what LSF issues after a while
        // once the above two signals have been sent and not acted upon. Apparently kills the job
        // instantly so that the exit status has not got time to be written into an .exitcode 
        // file and is not reported to the Nextflow master process - therefore the value 9 is
        // never seen here in practice; see below for actual value.
        // source of issue reported here https://github.com/nextflow-io/nextflow/issues/2847
        "SIGKILLNOW": 9,
        // supposedly the default value of $task.exitStatus; this is what it is set to when not 
        // set in the absence of an .exitcode file for the previous execution of the task, as
        // would happen in the case mentioned above
        "NOEXITCODE": 2147483647
    ].values()

    if (task.attempt > max_attempts) {
        return default_error_strategy
    }
    // ------------------------------------------------- //
    switch(task.exitStatus) {
        // if non scalable error, kill the pipeline without mercy
        case {it in MISC_EXIT_CODES}:
            // Ignore due to non-scalable error code
            return default_error_strategy

        // if scaling related error:
        case {it in SCALING_EXIT_CODES}:
            // Retry with more memory and longer time limit
            return 'retry'

        case {it == null}:
            /*
            If exitStatus is null as is the case on the first attempt return 'retry'
            */
            return 'retry'

        default:
            // Return the value of params.retry_strategy
            return default_error_strategy
    }

}

def k2r_escalate_memory_strategy(task, input_size_GB, b0=params.mem_k2r_b0, b1=params.mem_k2r_b1, f1=params.mem_k2r_f1, a2=params.mem_k2r_a2){
    /**
    * Escalate memory strategy for tasks.
    *
    * This function takes into account the input size in GB and applies a memory escalation strategy based on the task attempt number.
    *
    * The strategy involves linear regression to predict peak memory usage, with adjustments made based on the task attempt number.
    *
    * @param task    The task object
    * @param input_size_GB  The input size in GB
    * @param b0     Coefficient for linear regression
    * @param b1     Coefficient for linear regression
    * @param f1      Factor to multiply predicted peak memory usage (for second attempt)
    * @param a2      Additional memory allocation per attempt (in GB) after the first attempt
    *
    * @return  The escalated memory size in GB, taking into account the task attempt number and input size.
    */

    // predict peak mem
    peak_mem_pred = linear_regression_fit(input_size_GB,b0,b1)
    //println("${peak_mem_pred}, ${input_size_GB}, ${b0}, ${b1}")

    // if second try, add multiply predicted by factor 1 (f1)
    if (task.attempt == 2){
        return "${peak_mem_pred * f1} GB"
    }

    // if second attempt, add a2 gb to previous attempt
    if (task.attempt == 3){
        return "${(peak_mem_pred * f1) + a2} GB"
    }

    // keep adding a2 gb for each attempt
    if (task.attempt > 3) {
        return "${(peak_mem_pred * f1) + ((task.attempt) * a2)}"
    }

    // if first try, use linear regression
    return "${peak_mem_pred} GB"
}

process {
    errorStrategy = {retry_strategy(task, params.max_attempts, params.default_error_strategy) }
    max_retries = params.max_attempts

    withLabel:mem_k2r_escalate{
        //memory = "2 GB"

        memory = {k2r_escalate_memory_strategy(
                            task,
                            bytesToSize(meta.fqs_total_size, "GB"),
                            params.mem_k2r_b0_final,
                            params.mem_k2r_b1,
                            params.mem_k2r_f1,
                            params.mem_k2r_a2)}

    }

}
